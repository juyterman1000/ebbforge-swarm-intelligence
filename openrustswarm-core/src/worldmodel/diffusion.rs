//! Latent Diffusion dynamics
//!
//! Predicts future states by denoising random predictions.

use super::{LatentState, Prediction, WorldModelConfig};
use pyo3::prelude::*;
use rand::thread_rng;
use rand_distr::{Distribution, Normal};
use tracing::info;

/// Diffusion-based predictor
#[pyclass]
pub struct DiffusionPredictor {
    config: WorldModelConfig,
    diffusion_steps: usize,
}

#[pymethods]
impl DiffusionPredictor {
    #[new]
    #[pyo3(signature = (config = None))]
    pub fn new(config: Option<WorldModelConfig>) -> Self {
        let cfg = config.unwrap_or_default();
        info!("[DiffusionPredictor] Initialized");
        DiffusionPredictor {
            config: cfg,
            diffusion_steps: 10,
        }
    }

    /// Predict future latent states using iterative denoising
    /// 1. Start with noise
    /// 2. Condition on current state + action
    /// 3. Denoise iteratively
    pub fn diffuse_predict(
        &self,
        current: &LatentState,
        action_encoding: Vec<f32>,
        samples: usize,
    ) -> Vec<LatentState> {
        let mut predictions = Vec::new();
        let mut rng = thread_rng();
        let Ok(normal) = Normal::new(0.0, 1.0) else {
            return Vec::new();
        };

        for _ in 0..samples {
            // 1. Initial Gaussian Noise
            let mut latents: Vec<f32> = (0..self.config.latent_dim)
                .map(|_| normal.sample(&mut rng))
                .collect();

            // 2. Iterative Denoising
            // In a real diffusion model, this uses a denoising architecture.
            // Here we interpolate towards the expected deterministic mean.

            // Expected mean (based on simple transition logic from v8)
            let mut expected = vec![0.0f32; self.config.latent_dim];
            for i in 0..self.config.latent_dim {
                // Auto-correlation decay
                expected[i] = current.vector[i] * 0.95;
                // Action influence
                if i < action_encoding.len() {
                    expected[i] += action_encoding[i] * 0.1;
                }
            }

            // Denoise loop
            for step in 0..self.diffusion_steps {
                let alpha = (step as f32) / (self.diffusion_steps as f32); // 0 to 1

                // Mix noise with guided signal
                for i in 0..self.config.latent_dim {
                    latents[i] = latents[i] * (1.0 - alpha) + expected[i] * alpha;
                }
            }

            // Normalize result
            let norm: f32 = latents.iter().map(|x| x * x).sum::<f32>().sqrt();
            if norm > 0.0 {
                for v in &mut latents {
                    *v /= norm;
                }
            }

            predictions.push(LatentState::new(
                latents,
                current.agent_id.clone(),
                current.step + 1,
            ));
        }

        predictions
    }

    /// Predict sequence (just 1 step for now)
    pub fn rollout(&self, current: &LatentState, action_encoding: Vec<f32>) -> Prediction {
        // For rollout, we take 3 diffusion samples to capture uncertainty
        let samples = self.diffuse_predict(current, action_encoding, 3);

        // Return the mean prediction for simplicity, but we could return variance
        let best_guess = samples[0].clone();

        Prediction::new(vec![best_guess], 0.85, vec!["action".to_string()])
    }
}
